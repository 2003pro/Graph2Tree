{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-03T13:19:13.652977Z",
     "start_time": "2019-12-03T13:19:13.170089Z"
    }
   },
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "from src.train_and_evaluate import *\n",
    "from src.models import *\n",
    "import time\n",
    "import torch.optim\n",
    "from src.expressions_transfer import *\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "def read_json(path):\n",
    "    with open(path,'r') as f:\n",
    "        file = json.load(f)\n",
    "    return file\n",
    "\n",
    "def write_json(path,file):\n",
    "    with open(path,'w') as f:\n",
    "        json.dump(file,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-03T13:19:45.978987Z",
     "start_time": "2019-12-03T13:19:45.972996Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_new_fold(data,pairs,group):\n",
    "    new_fold = []\n",
    "    for item,pair,g in zip(data, pairs, group):\n",
    "        pair = list(pair)\n",
    "        pair.append(g['group_num'])\n",
    "        pair = tuple(pair)\n",
    "        new_fold.append(pair)\n",
    "    return new_fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-03T13:20:18.647260Z",
     "start_time": "2019-12-03T13:20:18.629691Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_mawps_data(filename):  # load the json data to list(dict()) for MAWPS\n",
    "    print(\"Reading lines...\")\n",
    "    f = open(filename, encoding=\"utf-8\")\n",
    "    data = json.load(f)\n",
    "    out_data = []\n",
    "    for d in data:\n",
    "        if \"lEquations\" not in d or len(d[\"lEquations\"]) != 1:\n",
    "            continue\n",
    "        x = d[\"lEquations\"][0].replace(\" \", \"\")\n",
    "\n",
    "        if \"lQueryVars\" in d and len(d[\"lQueryVars\"]) == 1:\n",
    "            v = d[\"lQueryVars\"][0]\n",
    "            if v + \"=\" == x[:len(v)+1]:\n",
    "                xt = x[len(v)+1:]\n",
    "                if len(set(xt) - set(\"0123456789.+-*/()\")) == 0:\n",
    "                    temp = d.copy()\n",
    "                    temp[\"lEquations\"] = xt\n",
    "                    out_data.append(temp)\n",
    "                    continue\n",
    "\n",
    "            if \"=\" + v == x[-len(v)-1:]:\n",
    "                xt = x[:-len(v)-1]\n",
    "                if len(set(xt) - set(\"0123456789.+-*/()\")) == 0:\n",
    "                    temp = d.copy()\n",
    "                    temp[\"lEquations\"] = xt\n",
    "                    out_data.append(temp)\n",
    "                    continue\n",
    "\n",
    "        if len(set(x) - set(\"0123456789.+-*/()=xX\")) != 0:\n",
    "            continue\n",
    "\n",
    "        if x[:2] == \"x=\" or x[:2] == \"X=\":\n",
    "            if len(set(x[2:]) - set(\"0123456789.+-*/()\")) == 0:\n",
    "                temp = d.copy()\n",
    "                temp[\"lEquations\"] = x[2:]\n",
    "                out_data.append(temp)\n",
    "                continue\n",
    "        if x[-2:] == \"=x\" or x[-2:] == \"=X\":\n",
    "            if len(set(x[:-2]) - set(\"0123456789.+-*/()\")) == 0:\n",
    "                temp = d.copy()\n",
    "                temp[\"lEquations\"] = x[:-2]\n",
    "                out_data.append(temp)\n",
    "                continue\n",
    "    return out_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-03T13:27:02.245089Z",
     "start_time": "2019-12-03T13:27:02.222316Z"
    }
   },
   "outputs": [],
   "source": [
    "def prepare_data(pairs_trained, pairs_tested, trim_min_count, generate_nums, copy_nums, tree=False):\n",
    "    input_lang = Lang()\n",
    "    output_lang = Lang()\n",
    "    train_pairs = []\n",
    "    test_pairs = []\n",
    "\n",
    "    print(\"Indexing words...\")\n",
    "    for pair in pairs_trained:\n",
    "        if not tree:\n",
    "            input_lang.add_sen_to_vocab(pair[0])\n",
    "            output_lang.add_sen_to_vocab(pair[1])\n",
    "        elif pair[-1]:\n",
    "            input_lang.add_sen_to_vocab(pair[0])\n",
    "            output_lang.add_sen_to_vocab(pair[1])\n",
    "    input_lang.build_input_lang(trim_min_count)\n",
    "    if tree:\n",
    "        output_lang.build_output_lang_for_tree(generate_nums, copy_nums)\n",
    "    else:\n",
    "        output_lang.build_output_lang(generate_nums, copy_nums)\n",
    "\n",
    "    for pair in pairs_trained:\n",
    "        num_stack = []\n",
    "        for word in pair[1]:\n",
    "            temp_num = []\n",
    "            flag_not = True\n",
    "            if word not in output_lang.index2word:\n",
    "                flag_not = False\n",
    "                for i, j in enumerate(pair[2]):\n",
    "                    if j == word:\n",
    "                        temp_num.append(i)\n",
    "\n",
    "            if not flag_not and len(temp_num) != 0:\n",
    "                num_stack.append(temp_num)\n",
    "            if not flag_not and len(temp_num) == 0:\n",
    "                num_stack.append([_ for _ in range(len(pair[2]))])\n",
    "\n",
    "        num_stack.reverse()\n",
    "        input_cell = indexes_from_sentence(input_lang, pair[0])\n",
    "        output_cell = indexes_from_sentence(output_lang, pair[1], tree)\n",
    "        # train_pairs.append((input_cell, len(input_cell), output_cell, len(output_cell),\n",
    "        #                     pair[2], pair[3], num_stack, pair[4]))\n",
    "        train_pairs.append((input_cell, len(input_cell), output_cell, len(output_cell),\n",
    "                            pair[2], pair[3], num_stack, pair[4]))\n",
    "    print('Indexed %d words in input language, %d words in output' % (input_lang.n_words, output_lang.n_words))\n",
    "    print('Number of training data %d' % (len(train_pairs)))\n",
    "    for pair in pairs_tested:\n",
    "        num_stack = []\n",
    "        for word in pair[1]:\n",
    "            temp_num = []\n",
    "            flag_not = True\n",
    "            if word not in output_lang.index2word:\n",
    "                flag_not = False\n",
    "                for i, j in enumerate(pair[2]):\n",
    "                    if j == word:\n",
    "                        temp_num.append(i)\n",
    "\n",
    "            if not flag_not and len(temp_num) != 0:\n",
    "                num_stack.append(temp_num)\n",
    "            if not flag_not and len(temp_num) == 0:\n",
    "                num_stack.append([_ for _ in range(len(pair[2]))])\n",
    "\n",
    "        num_stack.reverse()\n",
    "        input_cell = indexes_from_sentence(input_lang, pair[0])\n",
    "        output_cell = indexes_from_sentence(output_lang, pair[1], tree)\n",
    "        # train_pairs.append((input_cell, len(input_cell), output_cell, len(output_cell),\n",
    "        #                     pair[2], pair[3], num_stack, pair[4]))\n",
    "        test_pairs.append((input_cell, len(input_cell), output_cell, len(output_cell),\n",
    "                           pair[2], pair[3], num_stack,pair[4]))\n",
    "    print('Number of testind data %d' % (len(test_pairs)))\n",
    "    return input_lang, output_lang, train_pairs, test_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-03T13:24:01.252795Z",
     "start_time": "2019-12-03T13:24:01.244107Z"
    }
   },
   "outputs": [],
   "source": [
    "def change_num(num):\n",
    "    new_num = []\n",
    "    for item in num:\n",
    "        if '/' in item:\n",
    "            new_str = item.split(')')[0]\n",
    "            new_str = new_str.split('(')[1]\n",
    "            a = float(new_str.split('/')[0])\n",
    "            b = float(new_str.split('/')[1])\n",
    "            value = a/b\n",
    "            new_num.append(value)\n",
    "        elif '%' in item:\n",
    "            value = float(item[0:-1])/100\n",
    "            new_num.append(value)\n",
    "        else:\n",
    "            new_num.append(float(item))\n",
    "    return new_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-03T13:27:06.239750Z",
     "start_time": "2019-12-03T13:27:05.956199Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "Transfer numbers...\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "embedding_size = 128\n",
    "hidden_size = 512\n",
    "n_epochs = 80\n",
    "learning_rate = 1e-3\n",
    "weight_decay = 1e-5\n",
    "beam_size = 5\n",
    "n_layers = 2\n",
    "ori_path = './data/'\n",
    "prefix = '23k_processed.json'\n",
    "\n",
    "data = load_mawps_data(\"data/mawps_combine.json\")\n",
    "group_data = read_json(\"data/new_MAWPS_processed.json\")\n",
    "\n",
    "pairs, generate_nums, copy_nums = transfer_english_num(data)\n",
    "\n",
    "temp_pairs = []\n",
    "for p in pairs:\n",
    "    temp_pairs.append((p[0], from_infix_to_prefix(p[1]), p[2], p[3]))\n",
    "pairs = temp_pairs\n",
    "\n",
    "#train_fold, test_fold, valid_fold = get_train_test_fold(ori_path,prefix,data,pairs,group_data)\n",
    "new_fold = get_new_fold(data,pairs,group_data)\n",
    "pairs = new_fold\n",
    "\n",
    "fold_size = int(len(pairs) * 0.2)\n",
    "fold_pairs = []\n",
    "for split_fold in range(4):\n",
    "    fold_start = fold_size * split_fold\n",
    "    fold_end = fold_size * (split_fold + 1)\n",
    "    fold_pairs.append(pairs[fold_start:fold_end])\n",
    "fold_pairs.append(pairs[(fold_size * 4):])\n",
    "\n",
    "\n",
    "best_acc_fold = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-03T13:27:06.835299Z",
     "start_time": "2019-12-03T13:27:06.822976Z"
    }
   },
   "outputs": [],
   "source": [
    "for fold in range(5):\n",
    "    pairs_tested = []\n",
    "    pairs_trained = []\n",
    "    for fold_t in range(5):\n",
    "        if fold_t == fold:\n",
    "            pairs_tested += fold_pairs[fold_t]\n",
    "        else:\n",
    "            pairs_trained += fold_pairs[fold_t]\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-03T13:27:10.424883Z",
     "start_time": "2019-12-03T13:27:09.979697Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexing words...\n",
      "keep_words 1071 / 3132 = 0.3420\n",
      "Indexed 1074 words in input language, 20 words in output\n",
      "Number of training data 1537\n",
      "Number of testind data 384\n"
     ]
    }
   ],
   "source": [
    "input_lang, output_lang, train_pairs, test_pairs = prepare_data(pairs_trained, pairs_tested, 5, generate_nums,\n",
    "                                                                    copy_nums, tree=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-03T13:27:30.128460Z",
     "start_time": "2019-12-03T13:27:30.122110Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([3, 4, 5, 6, 2, 7, 8, 9, 10, 1, 11, 12, 13, 7, 14, 15, 16, 17, 1, 11, 7, 18, 19, 11, 20, 21, 22, 23, 2, 24], 30, [0, 12, 13], 3, ['8', '2'], [9, 18], [], [1, 2, 3, 9, 10, 11, 16, 17, 18])\n"
     ]
    }
   ],
   "source": [
    "print(train_pairs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-03T13:27:45.583208Z",
     "start_time": "2019-12-03T13:27:45.578774Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([2, 325, 6, 2, 105, 176, 268, 428, 2, 87, 2, 74, 1, 268, 17, 54, 12, 176, 1, 2, 91, 19, 268, 20, 98, 59, 17, 60], 28, [2, 12, 13], 3, ['56', '9'], [12, 18], [], [12, 13, 14, 18, 19, 20, 27, 28, 29])\n"
     ]
    }
   ],
   "source": [
    "print(test_pairs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
